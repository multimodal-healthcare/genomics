import os
import torch
import pandas as pd
import numpy as np

from tqdm import tqdm
from pathlib import Path
from pytorch_lightning.callbacks.base import Callback


class WriteCheckpointLogs(Callback):
    """
    Write final logs to neptune.
    """
    def on_epoch_end(self, trainer, pl_module):
        if isinstance(trainer.logger, list):
            logger = trainer.logger[0]
        else:
            logger = trainer.logger
        if torch.is_tensor(trainer.checkpoint_callback.best_model_score):
            logger.experiment.log_text("checkpoint_metric", trainer.checkpoint_callback.monitor)
            logger.experiment.log_text("checkpoint_value", str(trainer.checkpoint_callback.best_model_score.item()))
            logger.experiment.log_text("checkpoint_path", trainer.checkpoint_callback.best_model_path)


class WritePredictionsDataFrame(Callback):
    """
    Write Predictions generated by `predict_dataset` or `predict_dataset_with_uncertainty` that return pd.DataFrames.
    """
    def on_keyboard_interrupt(self, trainer, pl_module, device='cuda:0'):
        self.on_fit_end(trainer, pl_module, device)

    def on_fit_end(self, trainer, pl_module, device='cuda:0'): # how to set inference device better? adaptive to train device?
        # module = pl_module.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)
        module = trainer.get_model()
        ckpt = torch.load(trainer.checkpoint_callback.best_model_path)
        module.load_state_dict(ckpt['state_dict'])
        module.eval()
        module.to(device)

        time_max = 27 # effective real time max is time_max-2 -> 25 years
        times = [e for e in range(1, time_max, 1)]
        module.fit_isotonic_regressor(trainer.datamodule.train_ds, times, 100000)

        # write the predictions.csv
        outdir = os.path.join(Path(trainer.checkpoint_callback.dirpath).parent, "predictions")
        if not os.path.exists(outdir):
            os.mkdir(outdir)
        predictions = {}
        for ds_idx, ds in enumerate(tqdm([trainer.datamodule.train_ds, trainer.datamodule.valid_ds, trainer.datamodule.test_ds])):
            if ds_idx == 0:
                ds_name = "train"
            elif ds_idx == 1:
                ds_name = "valid"
            elif ds_idx == 2:
                ds_name = "test"
            predictions[ds_name] = module.predict_dataset_calibrated(ds, times)
            predictions[ds_name]['eid'] = ds.datasets[0].eid_map.index.values
            predictions[ds_name]["split"] = ds_name
        predictions_df = pd.concat([*predictions.values()]).reset_index(drop=True)
        predictions_df["partition"] = trainer.datamodule.cv_partition
        predictions_df["module"] = type(module).__name__
        try:
            predictions_df["net"] = type(module.net).__name__
        except AttributeError:
            pass
        predictions_df["datamodule"] = type(trainer.datamodule).__name__
        predictions_df["event_names"] = str(trainer.datamodule.event)
        predictions_df["feature_names"] = str(trainer.datamodule.features)
        #print(predictions_df.head())
        #print(predictions_df.dtypes)
        predictions_df.to_feather(os.path.join(outdir, "predictions.feather"))
        predictions_df.to_csv(os.path.join(outdir, "predictions.csv"))
        #print(os.path.join(outdir, ds_name + ".csv"))

        if isinstance(trainer.logger, list):
            trainer.logger[0].experiment.log_text("prediction_available", "TRUE")
            trainer.logger[0].experiment.log_text("prediction_path", os.path.join(outdir, "predictions.feather"))

        else:
            trainer.logger.experiment.log_text("prediction_available", "TRUE")
            trainer.logger.experiment.log_text("prediction_path", os.path.join(outdir, "predictions.feather"))

